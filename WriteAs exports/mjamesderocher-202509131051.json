{"username":"mjamesderocher","has_pass":false,"email":"matt@derocher.me","created":"2022-03-27T04:56:51Z","status":null,"subscription":null,"collections":[{"alias":"mjamesderocher","title":"Open Thoughts","description":"Musings about open, semantic web tech by Matt Derocher","style_sheet":"","public":true,"views":1816,"domain":"thoughts.delightfullabs.com","url":"https://thoughts.delightfullabs.com/","monetization_pointer":"","verification_link":"","total_posts":6,"posts":[{"id":"2x7w42sknsp6xk9y","slug":"thinking-as-you-go","appearance":"norm","language":"en","rtl":false,"type":"post","created":"2023-07-17T11:32:24Z","updated":"2023-07-17T11:32:23Z","title":"Thinking As You Go","body":"I am notorious for overthinking things. I have barely learned to swim because whenever I try to learn I overthink all the different parts of the process instead of just doing it. That is true about so many things in my life. Before I do something, I try to learn as much as I can about it.\n\nWhile learning both CSS and JavaScript, I read books, did courses, listened to podcasts, and watch conference presentations about the languages. What I did not do much of: coding with the languages. I did not really play around or experiment. I did some, but it was small compared to how much time I spent passively learning. I wanted to make sure that I really understood a subject and would avoid any pitfalls that are common to new developers. But the folly in that way of learning is twofold: \n\n1. You can never fully learn something. In the cases of CSS and JavaScript, the two languages were morphing and growing while I was learning, so even if I learned all the existing stuff, it wouldn’t prepare me for the new stuff.\n\n2. There are so many nuances of any subject that only reveal themselves when you are in the thick of trying to do something. They are fringe problems that you would not think of learning about beforehand because you didn’t even know they existed.\n\nI’d like to think I am getting better at not overthinking something before I try doing it, but I still have a long ways to go. I’ve been working on a web clipper with highlighting. I have been working on the code and almost have a Minimum Viable Product, but I’ve also gotten stuck at points when I had to make a technical decision and have spent a ton of time whiteboarding and reading about other projects that are doing similar things. The research has been useful, but just this past week I got back into the coding process. What came up quickly was that there were some nuances of the code that I hadn’t even considered being an issue during my research phase. The research was helpful, but it didn’t give me all the answers. The only way to think through something completely is to think about it as you are actively doing it.","tags":[],"paid":false,"full_post_url":"","views":12,"likes":0,"collection":{"alias":"mjamesderocher","title":"Open Thoughts","description":"Musings about open, semantic web tech by Matt Derocher","style_sheet":"","public":true,"views":1816,"domain":"thoughts.delightfullabs.com","url":"https://thoughts.delightfullabs.com/","monetization_pointer":"","verification_link":"","total_posts":0}},{"id":"wrfhh0bm5v6kjnx3","slug":"thoughts-on-files-over-apps","appearance":"norm","language":"en","rtl":false,"type":"post","created":"2023-07-09T13:23:13Z","updated":"2023-07-09T22:03:49Z","title":"Thoughts on Files over Apps","body":"There's lots of nuance around files vs apps. There has been [an article](https://stephanango.com/file-over-app) that has gotten some people choosing sides between whether apps or files are better. I don't have a definitive answer, but here are some things to think about in this area.\n\nPart of the argument is that proprietary files lead to data loss because apps don't last forever. In theory, this is true, but MS Word files are proprietary and have been around for a very long time and can be read by other apps such as Libre Office.\n\nJSON is a file standard, but the data in the file can take unlimited shapes. There is no guarantee (or really, likelihood) that one app can understand JSON from another app without a lot of intervention. ([Cambria](https://www.inkandswitch.com/cambria/) is one solution for this.)\n\nEven plain text faces this interoperability problem. We have syntaxes, such as Markdown, that we use in our text, but there are many different flavors of Markdown that all do not necessarily work together. The more complex you get with adding special meaning to plain text with syntax, the harder it is to read.\n\nComplex things are also hard to write in text. A nicely formatted table is easy to read in Markdown (technically [MultiMarkdown,](https://fletcherpenney.net/multimarkdown/) since default Markdown doesn't have table support), but it is so difficult to write and edit and keep everything lined up. It is also easy to leave off a character needed for the syntax and have everything break when you run it through an interpreter.\n\nAlso, when we use syntax like Markdown, we break the semantics of special characters. A `*` symbol is originally used for defining footnotes (true its original meaning was arbitrary, as technically every symbol is), but in Markdown it can mean a bullet point or that text should be italicized. The original meaning has changed. We then have to escape these special characters when we try to use them as originally intended.\n\nI don't think there is a perfect solution. A theme that I am constantly bringing up in tech conversations is that every solution requires tradeoffs. I definitely see the benefits of text based files. In certain environments, text based files are the most versatile, such as on a desktop computer. Files can be indexed. There's command line tools to batch manipulate text files. Some operating systems even do version control for changes to text files. But all of these features are not inherent to the text file itself, but come from systems that have built up around the format.\n\nOn the web, because JavaScript so easily can manipulate JSON-like objects, JSON is winning as a favorite file format. There are tools to store, index, and batch-manipulate JSON files in the same way text files are handled on desktop environments. Again, it is not because JSON is inherently better, but because tools are there to make it powerful.\n\nThe problem with standards, is that unless absolutely everyone agrees to use it, then you have to find a way to inter-op with people who don't conform to the standard. From experience, I can safely say there will never be a time when we all agree on a standard. Even for something as simple as CSS there are dozens of different ways to write it and then it all gets compiled to CSS in the end (I personally prefer SASS). The fact that they all compile to the standard makes it less of an issue. You can use what you already know and works for you.\n\n\u003e Every medium for ideas is corruptible. There’s no magic file format. Most are likely to last long enough for you to convert to something else if need be. It’s more important to find the constraint that works for you.\n\u003e\n\u003e —[CJ Chilvers](https://www.cjchilvers.com/blog/is-plain-text-best/)\n\nI am currently working on an app for annotating documents. I have stalled because I am in a crisis about whether to save the annotations in an [atJSON](https://github.com/condenast/atjson) style offsets list or as [W3C JSON-LD Annotations](https://w3c.github.io/web-annotation/model/wd2/). I will probably need at some point to convert between the two, so the truth is, the format used to save it as is kind of trivial. You chose one format as the source of truth and convert to the other. From there, there are already existing tools to output JSON offsets as Markdown or HTML. (I am currently leaning towards W3C annotations, since they are more of a standard, but JSON offsets will be best for annotating content that is constantly changing.)\n\nSo if I am making an app, I may not put everything in a text file. But as long as I have a way for users to get their data out by export or automatic conversion to a common file format, then I believe I meet the criteria for longevity of data.","tags":[],"paid":false,"full_post_url":"","views":58,"likes":0,"collection":{"alias":"mjamesderocher","title":"Open Thoughts","description":"Musings about open, semantic web tech by Matt Derocher","style_sheet":"","public":true,"views":1816,"domain":"thoughts.delightfullabs.com","url":"https://thoughts.delightfullabs.com/","monetization_pointer":"","verification_link":"","total_posts":0}},{"id":"ucu9twmyeu75j02f","slug":"filtering-feeds","appearance":"norm","language":"en","rtl":false,"type":"post","created":"2023-02-01T14:47:18Z","updated":"2023-02-01T14:48:09Z","title":"Filtering feeds","body":"The primary way I use Twitter is through lists. I have two lists (both currently private): one for history and one for what I call “Future Web,” which is an assortment of people who are thinkers and practitioners that are working on the semantic web, tools for thought, web3 (though generally not the blockchain version but the IPFS and similar technologies version), and web archival.\n\nI use lists because I mostly use Twitter for learning. I have many different interests and at certain times my mind is more focused on one area. So when I am in the mood for history, I can open that list (props to Twitter for the new design on mobile that puts lists on the top of the screen so they are easy to access).\n\nI slowly add to these lists by checking out retweets from people already on my list. I also occasionally remove people from the list because the subject matter falls outside of my main interests. I add someone to Future Web because I want to see their thoughtful ideas about tech. If they start talking too much about politics, do too much self-promotion, or go on too many rants, I remove them from the list. This is hard to do because you feel a little guilty. Also, I don’t want to put myself in an echo chamber and only hear what I already believe about things, but I also have to acknowledge that my mental capacity is limited and I cannot read everything from everyone.\n\nI have used mute features at certain times when certain things had Twitter in an uproar. (I set a mute filter on the word “Twitter” after Twitter was bought by Musk. How meta is that?) But these filters are limited in their functionality. They can only block certain words, but cannot block ideas.\n\nLet’s give an example. If I didn’t want to have any tweets about Large Language Models (LLMs), such as ChatGPT in my feed, how would I do it? It would be pretty hard, because everyone, including people who you never would have thought would care about AI are talking about them. I could start by muting tweets with “ChatGPT” in them. But there are other language models, so I would also need to add words such as “GPT-3,”  “ESMFold,” “MT-NLG,” “OpenAI,” and “AI.” But some companies use generic words for their products. There is one language model named “Bloom.” If you added that to your list of muted words, you would probably block content that had nothing to do with LLMs.\n\nManually blocking keywords probably wouldn’t be enough to filter out content. There are so many words used for any subject and there is overlap of words which make it impossible to filter out a subject completely in this manner.\n\nArtificial intelligence, including (somewhat ironically, considering the example I chose) LLMs, is probably part of the solution. Though, I do have a hard time blindly putting my trust in AI. Facebook has the option to click on a post and “see fewer posts like this.” What exactly does that mean? It gives no clue of how it will filter out the content. And it might be thinking of different criterial than you are thinking. The post might be a picture of a cat in a cardboard box, and you click the button thinking it will show you fewer posts about cats, but the algorithm interprets it to mean you want to see fewer posts about cardboard boxes.\n\nI keep saying it, but I think the semantic web can help with this. It allows content to be concretely associated with concepts. I don’t think a writer of a social media post should have to tag each word with RDFa tags, but what if after a user posts, then AI can identify the concepts in the post. When I click on “see fewer posts like this” it can bring up a list of concepts found in the post. You can then manually select the concepts to remove from your feed.","tags":[],"paid":false,"full_post_url":"","views":71,"likes":0,"collection":{"alias":"mjamesderocher","title":"Open Thoughts","description":"Musings about open, semantic web tech by Matt Derocher","style_sheet":"","public":true,"views":1816,"domain":"thoughts.delightfullabs.com","url":"https://thoughts.delightfullabs.com/","monetization_pointer":"","verification_link":"","total_posts":0}},{"id":"y0tq60w0ki9qti44","slug":"ifttt-for-the-semantic-web","appearance":"norm","language":"en","rtl":false,"type":"post","created":"2023-01-31T13:40:04Z","updated":"2023-01-31T13:40:03Z","title":"IFTTT for the Semantic Web","body":"The semantic web is a beautiful promise. All data has real meaning and it can interoperate with all other data. I can write an article about Abraham Lincoln and mark it up with RDFa so that it is known who I am talking about. Then, some type of reasoning can be performed and search other datasets and get back info about Lincoln, such as when and where he was born, how tall he was, who his spouse was, etc.\n\nBut the problem is, there is no easy way to implement what I just described. There are people working on the idea. Some of the demos look very impressive. But for now, they are just demos. There are some JavaScript developer libraries that are aimed at making it easy to work with RDF data, but it seems like most of them aren’t ready for modern development (for example, most of the libraries I tried only work with Webpack, which was the main bundler a few years back, but new bundlers like Vite are becoming default). A lot of them are also created as part of a research project and then development seems to stop on them after the research is over.\n\nWhat I want is for all my data to work together. I want to be able to have a group of browser tabs associated with my to-do list. Then I can close the tabs, and reopen them in one click from my to-do app. I also want to be able to write notes in a separate app and include tasks in them that show up in the same to-do app. I want to be able to associate PDFs and other files with my to-do app—not in an upload attachment type of way, but just to reference a document that lives somewhere else from my to-do app.\n\nA lot of apps and services provide APIs. Some apps use APIs from other apps to create connections in their app. For example, a todo app can use a specific API from a specific calendar app to create a connection from your to-dos to your calendar. But that is just for one specific calendar app. There are many different calendar apps, and all of them have different APIs. So the developers have to learn them all and write up the connections.\n\nI remember when IFTTT (If This, Then That) first came out. It seemed like magic. It allowed you to connect so many different services, even if the developers of those apps didn’t write specific connections. I didn’t really know any kind of scripting at the time, so it allowed me to connect my different buckets of data together. Of course, it wasn’t perfect. Data syncing was just one-directional. The two data buckets didn’t actually know about each other. One data bucket just slurped in data that was passed to it. There was no way to update that data and send it back. (Of course, you could create some kind of connection back the other way, but it would create a new data entry and not really update the original data.)\n\nWhat if we had an IFTTT for the semantic web? What if I could set up connections between data sets without knowing any coding? I’m not exactly sure what it would look like. Since most RDF data exposes SPARQL endpoints, that would probably be the connecting secret sauce. (There is also [Project Cambria](https://www.inkandswitch.com/cambria/), which is a non-semantic-web way of connecting two different data sources together.) We would still need tools to make authoring RDF data easier. And easier ways to integrate RDF data into our development. These would be the foundations to make something like this even possible.","tags":[],"paid":false,"full_post_url":"","views":81,"likes":0,"collection":{"alias":"mjamesderocher","title":"Open Thoughts","description":"Musings about open, semantic web tech by Matt Derocher","style_sheet":"","public":true,"views":1816,"domain":"thoughts.delightfullabs.com","url":"https://thoughts.delightfullabs.com/","monetization_pointer":"","verification_link":"","total_posts":0}},{"id":"qxohpukzbaeb8om4","slug":"a-tools-for-thought-ecosystem","appearance":"norm","language":"en","rtl":false,"type":"post","created":"2022-11-12T15:55:33Z","updated":"2022-11-14T13:06:18Z","title":"A Tools for Thought Ecosystem","body":"There is no lack of Tools for Thought (TfT) applications today, but all of them require you to store all your data in one application. What if we could figure out a way to use different apps for different tasks but work from the same documents and data?\n\n## Motivation\n\nI am a history buff. Not in the normal way of going to museums or watching documentaries, but in the way of searching for hours through digital newspaper archives looking for certain information to answer a question and then writing about what I found.\n\nI used to use Evernote as a system for managing research for history writing. Evernote has an excellent web clipper, so it was really easy to get things into it. It was not so easy to do anything with the notes and files when they were inside it. I tried creating an elaborate system of notebooks (folders) and tags and internal links, but it became obvious that the app was not meant for that level of use.\n\nEvernote can store any kind of file, but it can only open a handful of file types. I would open the different file types in separate reader apps, each of which had a unique annotation system. I was able to get Evernote to pull in most of the annotations using various hacks, but the sync was one-directional and the annotations were not linked back to the source.\n\nI built a system on top of Sanity, which is a hosted, headless CMS. It was really easy to create data types, so I could have entities like people, places, or dates that could be linked to in blog posts. They have a powerful query language, so I was able to list all posts that mentioned an entitiy. I created an auto-fill component in the CMS that would let you search Wikidata for an entity and it would populate information, like name, date of birth, and a description. I also started building a web clipper that would help me collect data into the system.\n\nAt first, I liked the system and was able to use it post some research, but I eventually decided to move away from this solution, too. Besides some quirks and limitations in the API (some of which have been fixed since I tried the project), the main issues I had with the platform were that it wouldn't work offline and the only option was for Sanity to host your data.\n\n## Guiding ideas\n\nMy goal is for researchers to be able to collect digital sources (websites, documents, media files, and named entities), make annotations on any file type, use these sources and annotations in their writing, and then link back to the original sources.\n\n### Avoid lock-in\n\nI have heard about some powerful and popular Tools for Thought applications. I haven't deeply used any of them, because, after my experience with Evernote, I am afraid of getting locked into something that doesn't quite meet my needs. I want to explore ways for people to be able to use my apps without feeling that it is all or nothing.\n\n### Small apps for specific tasks\n\nIn the old days when we had all our files on our local hard drives, we could use many small applications that had very specific uses. I want to try to capture that flexibility and interoperability between apps. Instead of creating one app that does all the things I need, I can create smaller apps that handle specific activities but can all understand the same files and data.\n\nSmaller apps also mean faster development time and they avoid the complexity and slowness that can come with apps that try to do too much.\n\n### Interoperability\n\nIf each tool is opt-in, then other developers could create apps that work in the ecosystem. The user could use them without having to stop using the other apps they have been using. To increase this possibility of interoperability, as much as possible, I want to take advantage of standards like RDF or JSON-LD.\n\n## Components of the ecosystem\n\nThese are the current pieces of the ecosystem that I am working towards:\n\n1. **Web Clipper** - Save web pages, PDFs, EPUBs, and media files. I have started on this and have a [basic implementation](https://github.com/delightful-labs/delightful-clipper) (almost) working.\n\n2. **Reader** - Read all different files with user preferences and the ability to highlight and annotate. Annotations also can include Named Entity Recognition to find names of people and places in the content. I currently have a basic reader (without annotations) combined with the clipper, though they will probably be separated at some time.\n\n3. **Annotation manager** - A way to view all your annotations in one place. This would probably be a stepping stone to the studio, as mentioned in the next point.\n\n4. **Authoring Studio** - Write and combine annotations into notes or blog posts. I imagine something close in concept to current TfTs like Roam or Tana.\n\nBesides these, the possibilities are many, including Dropbox-like local sync or an app that would take a video or audio file, create a transcript with voice-to-text, and then allow annotations on the content.\n\n## Technical foundations\n\n* **Content addressing** (IPFS, WNFS) - If I have a copy of a PDF and you have a copy, then we can \"talk\" about the same file. This will also increase the lifetime of a source document because multiple people can host the file (this cuts down on link rot).\n* **Stand-off properties** ([atJSON](https://github.com/condenast/atjson), [W3C web annotations](https://w3c.github.io/web-annotation/model/wd2/)) - To preserve content addressing, we want to manipulate source documents as little as possible. Stand-off properties allow each user to have their own annotations on a shared document. These properties are essentially optional _layers_ on top of the source document. ![](https://i.snap.as/oqLatDSw.png)\n* **Semantic data** (RDF, JSON-LD) - There have to be ways for other applications to know what is being talked about. It will also allow you to find relations between items that you have collected.\n* **Collaboration/interoperability** (Activity Pub, Linked Data Notifications) - This would allow people to join groups and get notifications when someone made annotations on a document I have an interest in.\n* **Offline access** (WNFS) - It is important for me that apps are fast and accessible at all times because I spend a lot of time in Africa where there is metered and sometimes spotty network access.\n\n## Conclusion\n\nI have been working on this part-time as a side project when I am not working for my day job as a front-end developer. Inspired by Linus Lee's ideas of creating tools that you would use yourself, I am trying to get to what I am calling MMP (Minimum Matt Product) so that I can use these tools in my research and everyday reading. If I can get it to where I will use it every day, then I will keep working out the details so that it can be usable by more people.","tags":[],"images":["https://i.snap.as/oqLatDSw.png"],"paid":false,"full_post_url":"","views":369,"likes":0,"collection":{"alias":"mjamesderocher","title":"Open Thoughts","description":"Musings about open, semantic web tech by Matt Derocher","style_sheet":"","public":true,"views":1816,"domain":"thoughts.delightfullabs.com","url":"https://thoughts.delightfullabs.com/","monetization_pointer":"","verification_link":"","total_posts":0}},{"id":"1lyfvh1ucl4aeugo","slug":"two-steps-forward-one-step-backwards","appearance":"norm","language":"en","rtl":false,"type":"post","created":"2022-04-07T05:01:34Z","updated":"2022-04-07T05:26:53Z","title":"Two Steps Forward, One Step Backwards","body":"## The promise of technology\n\nThere was a time in my late teens/early twenties when I was enamored by technology. I had swapped out my Windows laptop for a Macbook Pro. Every week, I eagerly awaited the new episode of the Mac Power Users podcast. While waiting for the new episode, I would work through the backlog.\n\nI was fascinated by what were called “workflows” and how different apps could be automated and pass data back and forth between each other. This was achieved using applications like Automator, TextExpander, Hazel, and Alfred. These apps came with a semi-hefty price tag (at least it seemed so for a teen that worked at Subway), but it was a one-time price, so if you bought it, you owned it forever. Sometimes upgrades to major versions cost money, but you could opt out and still use the old version.\n\nSpotlight indexed everything on the computer, so I could search and see my Evernote notes right next to my emails and Pages documents. Apps like Picasa and iTunes also indexed your photos and music, respectively. You had all your data in your control, and you could use a Time Capsule and/or Carbon Copy Cloner to seamlessly make sure if something happened to your computer, you wouldn’t lose your files. (I used both and also Carbonite for off-site backup.)\n\nDropbox came out, and it was like magic! You could sync all your files between devices. You still maintained full control over them. Mobile apps would connect to the Dropbox API, so it would even (sorta) work on your phone and tablet.\n\n## Broken promises\n\nFast forward to today, and I’ve lost almost all of that fascination with technology. I work on the web, so I am at a computer more than ever before in my life. I switched my laptop back to Windows partly because I refused to pay the “Apple tax” and partly as a protest against Apple’s ethos of a walled garden.\n\nI don’t buy a new phone every year anymore, either. I’ve had the same phone for three years, and I’m hoping to get at least one more year out of it.\n\nThere are quite a few reasons why my feelings about technology have changed. Some of them are personal, and some are because of how technology evolved.\n\n### Personal growth\n\nI’ll start with some positive reasons. It’s kind of simple: I’ve matured as a human being. I am more thoughtful about how I spend my money. My three-year-old phone does basically all that a new phone does. It has a good camera, and people still give me compliments about how good the camera is. Unless it breaks or you have something significantly different to offer, why would I upgrade? (I have been tempted more than once to buy a foldable phone because it **is** extremely different than what I have.)\n\nI also want to spend less time on technology. I don’t want to be identified by technology. I don’t want to be either “the guy who’s always on his phone” or “the computer guy.” (Not really positive that I’ve succeeded in this, but I’m trying in some ways.)\n\n### The Internet changed everything (and not all for the good)\n\nGoing back to talk about the tech itself, everything is different because the Internet has gotten so much more powerful. You don’t **need** to have your laptop do a bunch of automation stuff anymore because everything is done on the web. In fact, as things move to the web, there are some things that are no longer possible to manipulate on a computer. Companies like Twitter and Facebook have changed how their APIs work, so what can be retrieved from them is limited. We have online-only file formats such as Figma that can’t be accessed without the Internet.\n\nInstead of controlling your data and syncing it with a service of your choice, companies all have their own proprietary ways of managing your data.\n\nBecause they have control of your data and you can’t easily access it without the company, they can charge money each month for you to be able to access your data. (Is it an exaggeration to call it ransomware?) Every service charges for their one little utility, and at even $2.99 a month for a service, in less than a year, it is much more expensive than most of the one-off apps you bought for the laptop. Surprisingly, even though they already charge a subscription price, many also sell your data to advertisers.\n\nThere is web automation in the form of IFTT and Zapier, but they don’t really match the power of Hazel and the like.\n\nNot to mention, web stuff seems really buggy. It is never finished, so it seems to be in a constant flux of features being added that also add bugs.\n\n## Making new promises\n\nAll that said, I haven’t given up on technology. I may not like where it is, but I am hopeful for what it can become. The web is powerful, and it opens up possibilities that weren’t available when things stayed locally on our separate computers. It’s going to take time for things to be as seamless as they felt on local computers because things are a hundred times more complicated on the web. There are issues of security, scale, and interoperability. And, yes, these things will take time and effort to figure out, so there will need to be a constant stream of money to make it progress. (Exactly how and to whom this money should be directed is a large discussion in itself.)\n\nI still listen to technology podcasts (and read blogs and books), but the focus isn’t on using existing tech and apps. But it is on how we can make better tech that solves these problems. There are many smart people looking to solve these problems. They want to help the web reach its potential.\n\nI am starting this blog because I want to bring more notice to the people working on these things and also add my ideas to the conversation.","tags":[],"paid":false,"full_post_url":"","views":168,"likes":0,"collection":{"alias":"mjamesderocher","title":"Open Thoughts","description":"Musings about open, semantic web tech by Matt Derocher","style_sheet":"","public":true,"views":1816,"domain":"thoughts.delightfullabs.com","url":"https://thoughts.delightfullabs.com/","monetization_pointer":"","verification_link":"","total_posts":0}}]}],"posts":[{"id":"sxi4warb0vref1au","slug":null,"appearance":"","language":"en","rtl":false,"type":null,"created":"2022-11-13T22:19:32Z","updated":"2022-11-14T12:55:37Z","title":"The Timeline is the problem","body":"\u003e a decentralized or federated timeline is still a timeline, and for me, the timeline is the problem.\n\u003e\n\u003e https://www.robinsloan.com/lab/specifying-spring-83/#summer\n\nBeing new is the main reason we are shown something nowadays. (Exception is Facebook memories of on this day posts.) Even search filters help you limit to past year, month, or week.\n\n“Meaningful” is hard to categorize, since it is subjective to the user. With the ungodly amount of data big tech has collected from us, they still fail in the most part to show content that I am actually interested in.\n\nWe could move back to being a web. Where links take us on trails to different places.","tags":[],"paid":false,"full_post_url":"","views":0,"likes":0},{"id":"tmr5mahy9nrk5wdg","slug":null,"appearance":"","language":"en","rtl":false,"type":null,"created":"2022-11-13T17:06:49Z","updated":"2022-11-16T12:04:05Z","title":"Semantic Quotations","body":"RDF is a kind of footnote for both humans and machines. It can explain intent without having to articulate it each time.\n\nWho said it first? When a quote is used, how do we know if it is a quote or the source? A computer would have to have index all texts from documents. It will have to know the date of when text the texts were published. Then it would compare the dates to see which one came first.\n\nThere are so many motivations when one work quotes another. Sometimes it is used to support an idea. Sometimes it is done to disprove the original idea. Sometimes it is used in a mocking form of irony. I can know the same words are being used, though I cannot always know the exact intent of the author. The quotation may also be accidental. If I have a dog named Spot who is running after a squirrel, and I shout “see Spot run!” am I necessarily quoting from Dick and Jane? If it was not my intention, then we would say it is a coincidence that the same words were used. In modern written text, we have quotation marks for to help notate when we are purposely citing someone else. Older forms of writing and spoken communication don’t have this. Some speakers are careful to verbally clarify by saying “begin quote” and “end quote,” but for speed and flow these details are often not done. Sometimes a speaker uses air quotes (usually for irony) but a transcript of a speech will likely not contain that.\n\n“This is the way” is a quotation from the Mandalorian. But it is also part of a quote from Jesus. Many times, when people use it, they are referring to one original usage or the other.\n\nFor past documents, the best we can do is guess. But when we write with modern tools, we should be able to give more metadata about our intent when we quote someone else.","tags":[],"paid":false,"full_post_url":"","views":0,"likes":0},{"id":"461cahmli1rfivhi","slug":null,"appearance":"","language":"en","rtl":false,"type":null,"created":"2022-11-13T16:09:53Z","updated":"2022-11-13T17:00:12Z","title":"Standoff Properties","body":"What gives me the right to impose my format on text? (The tyranny of markup)\n\nSome research into standoff properties comes from the digital humanities. If there is a spelling mistake in the original source, I should not edit the original source. But for sake of easier reading, we can add annotations that fix the mistake. This annotation layer can be combined with the original text in the rendering process.\n\nIn newspaper articles, many different font styles are used. I may want some of these headings to display as an h2 or h3 in my CMS, but it isn’t likely that the editor was thinking of those specific levels when he created the text. He was not concerned with the semantics, but the visual appearance that brought attention to a piece of text to show its importance.\n\nStandoff properties limits fragmentation of source texts. Instead of creating many different versions of a text, we have one source version and we all add our layers on top of it.\n\nStandoff properties handle overlap in markup.\n\nThere are tradeoffs. Information is split up among various files instead of being self-contained.\n\nIf a PDF encloses all highlights, then each time an annotation is added, then the whole file has to be saved and uploaded if stored remotely.","tags":[],"paid":false,"full_post_url":"","views":0,"likes":0},{"id":"240mtrnqsdm4ezgm","slug":null,"appearance":"","language":"en","rtl":false,"type":null,"created":"2022-07-19T10:52:39Z","updated":"2022-11-13T17:39:13Z","title":"Variations","body":"## Names\n\n“What’s in a name?” My parents put the name “Matthew” on my birth certificate. Many people call me “Matt.” In Tanzania, they call me “Mathayo.” On most social platforms I am “mjamesderocher.” Even a name is a complicated thing because it means something different to different people. Usually “Matthew” is considered to be my “first name,” but it can also be called a “given name” or a “Christian name.” In China, the first name is the family name. In Tanzania, people think my father’s name was James (it wasn’t), because the second name in Tanzania is your father’s name.\n\n## Book editions\n\nWhat is a book? It seems like a very easy question util you start thinking about the details.\n\nThere are different editions where the author and/or publisher have made corrections or additions. There is usually an updated preface giving a general overview of what has changed. But I am more thinking of variations of the same edition.\n\nPrinting errors\n\nAudio book\n\nKindle version\n\nReader’s annotations and underlines\n\nScan of paper book\n\n## Multiple files on the web\n\nSometimes the variation is location based. On the web, we use URLs to point to something. A PDF can be uploaded to infinitive locations on the web. Which one is the true source? If the files is the same, they all are equal in a technical sense. But the author might have a preferred location for you to download it from because either they want you to pay for it from them or they just want to keep track of download metrics.\n\nOnce a file is downloaded, it’s link to it’s original URL is lost, unless there is text in the PDF that mentions the download URL. many academic papers include a cover letter that has a URL like this so the paper can easily be referenced.\n\nAnother location-based variation is that complete information about someone or something is not all kept on one web page. A person can have a personal blog, social media profiles, and a Wikipedia page written about them. Which one of them is their digital home? Which one do I link to if I am talking about that person?\n\nOWL sameas\n\n## Content addressing\n\nIf I create a file that says “Hello world” and you save it to IPFS and you create a file that says “Hello world” then they have the exact same content address. Virtually, they are the same file. But any variation of the content changes the CID. If my file has an exclamation point at the end of it or even a space or new line character, then it has a different CID.\n\n## Standoff markup\n\n\u003e It is also clear that, to be reusable and readable, plain text must be virtually complete and coherent. Hence internal variations in the form of additions, deletions or other divergences cannot be permitted. This may seem an impossible constraint to allow, since virtually any manuscript sources, even ancient papyri and inscriptions, contain erasures and insertions, substitutions and transpositions, and even printed texts contain errors that must be corrected.\n\u003e\n\u003e https://www.semanticscholar.org/paper/Standoff-properties-as-an-alternative-to-XML-for-Schmidt/6056afc3c25fcf0e9b3e677c04ea4bc34b8151ab\n\n## Text fragments\n\nhttps://web.dev/text-fragments/\n\nText fragments are a way to link to certain text on the web. It’s basically like “find in page” built into the URL. Go to this address and then search to this text and jump to it. Because it is not looking for a certain character position, then I could edit the page and add or delete paragraphs and the link would still work. It is interesting to think about using something similar to link to information across different file variations of one book. I could save a highlight in my database and locate it in any version of the work, whether it be ePub, PDF, plain text, or even audio if it has a transcription.\n\nOf course it couldn’t work for all kinds of markup. If I wanted to use a search system to make bold just a single instance of one word, it would be impossible. If I searched for the word “the” and had in mind a specific instance of it, I couldn’t select just the one I wanted.","tags":[],"paid":false,"full_post_url":"","views":3,"likes":0},{"id":"xakkbr0urnn0sxgn","slug":null,"appearance":"","language":"en","rtl":false,"type":null,"created":"2022-07-19T10:13:33Z","updated":"2022-07-19T23:40:10Z","title":"Tradeoffs","body":"Boat cars\n\nApple watch\n\nStandoff markup vs all in one\n\n\u003e Files are at some level a hack, I get that, there are limits but they are an extremely useful and flexible hack. Like the QWERTY keyboard, they are “good enough” for most tasks. Files encapsulate a ‘chunk’ of your work and allow that chunk to be seen, moved, acted on, and accessed by multiple people and more importantly external 3rd party processes.\n\u003e\n\u003e https://jenson.org/files/","tags":[],"paid":false,"full_post_url":"","views":18,"likes":0},{"id":"d48hcs4ph1pkll54","slug":null,"appearance":"","language":"en","rtl":false,"type":null,"created":"2022-07-15T10:53:10Z","updated":"2022-07-15T10:53:09Z","title":"Web apps vs. Sites (No, it has nothing to do with tech)","body":"It’s a very tired argument. What is the difference between web sites and web apps. Or if there even a difference between the two?\n\nMany times the argument is that web apps are built with JS. Early web apps meant single page apps without URLs. But with tech like Next.js and Sveltekit that use URL routes as the main way of organizing your app, most apps can have URLs.\n\n* Web sites have URLs for everything\n* Web sites have public-facing content (On Github, if you don’t have access to a repo, the URL shows as 404 and not “Sign in to get access to this.” Probably because of privacy, because a URL can give away a lot of information.)\n* Web sites have content visible by default (when published). Web apps have content hidden by default.\n* Web sites have a concept of published or done. Web apps contain never finished content.\n* Websites have the longevity of content in mind. In an app, my content is very much tied to my account. If I close my account, my content is gone. I have to specifically share with others. On a site like WordPress, I can create content and by default other users can edit and access it.","tags":[],"paid":false,"full_post_url":"","views":0,"likes":0},{"id":"gjal8bahg3g5cls1","slug":null,"appearance":"","language":"en","rtl":false,"type":null,"created":"2022-03-28T04:08:12Z","updated":"2022-03-28T04:08:12Z","title":"note or blog post","body":"James Long changed his site so that all posts are just notes.","tags":[],"paid":false,"full_post_url":"","views":0,"likes":0},{"id":"3z67657nziy7boex","slug":null,"appearance":"","language":"en","rtl":false,"type":null,"created":"2022-03-28T04:06:18Z","updated":"2022-04-07T06:49:05Z","title":"Interop as a winning force","body":"The tool that most advanced tools for thought in recent years is Markdown. It was\n\nA CMS platform that has a json based block text editor. (I'm not going to name the company, because I'm not intending to shame them.) To much fanfare, they released the json format as open source. The wording made it seem like they thought it would be the future of block based editing on the web. But it hasn't gone anywhere beyond their own internal use. The explanation for this is simple: they provided no tools for the standard to be used outside of their CMS. No JS library to help translate a textarea to the JSON format and virtually no documentation.\n\nMarkdown released with tools to convert it to HTML.\n\n## Simplicity is nonthreatening\n\nMarkdown was simple. That's why it gained so much traction. You could write it anywhere, even places that didn't officially support it, and it still made visual sense. It is human readable.\n\nIt used only characters that could be easily typed on the keyboard.\n\nThere were only a handful of rules included with the original spec. It was so simple, that there is no end to different flavors of MD being created to add “missing” features to it.\n\nHumans are highly opinionated. The only way something can really gain popularity is if it is simple enough to not go against the way someone already thinks. (Of course you will still have some snobbish people who will discredit it because it is too simple.)\n\n## Too much freedom is paralyzing\n\nRFD is extremely simple in its syntax.  And because of blank nodes, the open world assumption, and ontologies, such as OWL's sameas, it can be used anywhere and interop with anything. It is because it is so open that people don't quickly adopt it. It's too powerful.\n\n## The future\n\nThe block protocol is aiming to bring interop to blocks on the web. It is an exciting idea, but it is too early to see if it will succeed.\n\nFission interop meetup videos\n\nProtocols\n\nBut even protocols aren't enough (difference of idea in Social working group)\n\nLenses\n\nCambria","tags":[],"paid":false,"full_post_url":"","views":0,"likes":0}]}